```
accelerate config

#In which compute environment are you running? ([0] This machine, [1] AWS (Amazon SageMaker)): 0
#Which type of machine are you using? ([0] No distributed training, [1] multi-CPU, [2] multi-GPU, [3] TPU [4] MPS): 2
#How many different machines will you use (use more than 1 for multi-node training)? [1]: 
#Do you want to use DeepSpeed? [yes/NO]: 
#Do you want to use FullyShardedDataParallel? [yes/NO]: 
#How many GPU(s) should be used for distributed training? [1]:
#What GPU(s) (by id) should be used for training on this machine as a comma-seperated list? [all]:
#Do you wish to use FP16 or BF16 (mixed precision)? [NO/fp16/bf16]: 
```
